# mini-VLBERT

### 대상 논문
VL-BERT: Pre-training of Generic Visual-Linguistic Representations
https://arxiv.org/abs/1908.08530

![image](https://user-images.githubusercontent.com/78068615/136225565-09478859-d064-4274-8f80-68df3ab7a5de.png)


### 참고한 링크
- building model: https://github.com/jackroos/VL-BERT/blob/master/common/visual_linguistic_bert.py
- pretraining: https://github.com/jackroos/VL-BERT/blob/master/pretrain/modules/resnet_vlbert_for_pretraining.py
